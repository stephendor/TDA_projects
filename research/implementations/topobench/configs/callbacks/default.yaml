defaults:
  - model_checkpoint
  - early_stopping
  - model_summary
  - model_timer
  - _self_

model_checkpoint:
  dirpath: ${paths.output_dir}/checkpoints
  filename: "epoch_{epoch:03d}"
  monitor: ${get_monitor_metric:${dataset.parameters.task},${dataset.parameters.monitor_metric}} #
  mode: "${get_monitor_mode:${dataset.parameters.task}}"
  save_last: False
  auto_insert_metric_name: False
  save_weights_only: False

early_stopping:
  monitor: ${get_monitor_metric:${dataset.parameters.task},${dataset.parameters.monitor_metric}} #${callbacks.model_checkpoint.monitor}
  patience: 25
  mode: "${get_monitor_mode:${dataset.parameters.task}}" #${callbacks.model_checkpoint.mode}

model_summary:
  max_depth: -1

learning_rate_monitor:
  _target_: lightning.pytorch.callbacks.LearningRateMonitor
  logging_interval: "epoch"
Validation Console Output - real_data_deep_tda_breakthrough
Timestamp: 20250806_143310
Random Seed: 42
================================================================================

[2025-08-06T14:34:41.135313]
STDOUT:
üöÄ REAL DATA DEEP TDA BREAKTHROUGH VALIDATION
================================================================================
Revolutionary approach: Deep TDA on real CIC-IDS2017 APT attacks
Target: 90%+ F1-score on actual infiltration attack patterns
Method: TDA-native deep learning preserving topological attack signatures
Dataset: Real APT infiltration attacks from CIC-IDS2017
================================================================================

üìä REAL APT DATA LOADING
üîß LOADING REAL CIC-IDS2017 INFILTRATION DATA
------------------------------------------------------------
Loading: /home/stephen-dorman/dev/TDA_projects/data/apt_datasets/cicids2017/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv
‚úÖ Dataset loaded: (288602, 79)
Columns: 79

Label Distribution:
  BENIGN: 288566 (99.99%)
  Infiltration: 36 (0.01%)

Data cleaning:
  Initial NaN values: 18
  Initial Inf values: 396
  Final NaN values: 0

Label Encoding:
  0: BENIGN
  1: Infiltration

Selected 20/20 key features for TDA analysis

Final data shape: (288602, 20)
Label shape: (288602,)
Attack rate: 0.0001 (36 attacks)

üîÑ CREATING TEMPORAL SEQUENCES FROM REAL DATA
--------------------------------------------------
Input shape: (288602, 20)
Sequence length: 50
Overlap: 0.3
  Processed 1000 sequences...
  Processed 2000 sequences...
  Processed 3000 sequences...
  Processed 4000 sequences...
  Processed 5000 sequences...
  Processed 6000 sequences...
  Processed 7000 sequences...
  Processed 8000 sequences...
‚úÖ Created 8245 temporal sequences
   Sequence shape: (8245, 50, 20)
   Attack rate: 0.0061 (50 attack sequences)
   Benign sequences: 8195

‚öñÔ∏è DATASET BALANCING FOR TRAINING
Attack sequences available: 50
Benign sequences available: 8195
‚ö†Ô∏è WARNING: Very few attack sequences. Results may not be representative.
‚úÖ Balanced dataset:
   Total sequences: 200
   Attack sequences: 50 (25.0%)
   Benign sequences: 150 (75.0%)

üîß FEATURE SCALING
‚úÖ Features scaled: (200, 50, 20)
   Mean: -0.000000
   Std: 1.000000

üìä TRAIN-TEST SPLIT
Train: 160 sequences
  - Attack: 40 (25.0%)
  - Benign: 120 (75.0%)
Test: 40 sequences
  - Attack: 10 (25.0%)
  - Benign: 30 (75.0%)
‚úÖ Data loaders created with batch size: 32

üß† DEEP TDA MODEL INITIALIZATION
Model parameters: 5,264,903
Architecture: Differentiable PH + Persistent Attention + Transformer
Ready for real APT attack pattern learning

üöÄ TRAINING ON REAL APT DATA
Training on: cpu
  Batch 0/5: Loss = 0.6288
Epoch 1/50:
  Train Loss: 0.7635, Train Acc: 28.75%
  Val Loss: 0.7080, Val F1: 0.7262
  ‚úÖ New best model saved: F1 = 0.7262
------------------------------------------------------------
  Batch 0/5: Loss = 0.7365
Epoch 2/50:
  Train Loss: 0.7093, Train Acc: 72.50%
  Val Loss: 0.7031, Val F1: 0.6304
------------------------------------------------------------
  Batch 0/5: Loss = 0.6463
Epoch 3/50:
  Train Loss: 0.6674, Train Acc: 77.50%
  Val Loss: 0.6740, Val F1: 0.7143
------------------------------------------------------------
  Batch 0/5: Loss = 0.6850
Epoch 4/50:
  Train Loss: 0.6759, Train Acc: 43.12%
  Val Loss: 0.6751, Val F1: 0.5202
------------------------------------------------------------
  Batch 0/5: Loss = 0.6114
Epoch 5/50:
  Train Loss: 0.6585, Train Acc: 57.50%
  Val Loss: 0.6784, Val F1: 0.7078
------------------------------------------------------------
  Batch 0/5: Loss = 0.6681
Epoch 6/50:
  Train Loss: 0.6544, Train Acc: 69.38%
  Val Loss: 0.6777, Val F1: 0.7078
------------------------------------------------------------
  Batch 0/5: Loss = 0.6270
Epoch 7/50:
  Train Loss: 0.6451, Train Acc: 71.88%
  Val Loss: 0.6733, Val F1: 0.7462
  ‚úÖ New best model saved: F1 = 0.7462
------------------------------------------------------------
  Batch 0/5: Loss = 0.6107
Epoch 8/50:
  Train Loss: 0.6415, Train Acc: 71.88%
  Val Loss: 0.6663, Val F1: 0.7266
------------------------------------------------------------
  Batch 0/5: Loss = 0.6821
Epoch 9/50:
  Train Loss: 0.6345, Train Acc: 67.50%
  Val Loss: 0.6619, Val F1: 0.7073
------------------------------------------------------------
  Batch 0/5: Loss = 0.6574
Epoch 10/50:
  Train Loss: 0.6476, Train Acc: 66.25%
  Val Loss: 0.6598, Val F1: 0.7073
------------------------------------------------------------
  Batch 0/5: Loss = 0.6814
Epoch 11/50:
  Train Loss: 0.6389, Train Acc: 68.12%
  Val Loss: 0.6331, Val F1: 0.7085
------------------------------------------------------------
  Batch 0/5: Loss = 0.5937
Epoch 12/50:
  Train Loss: 0.6404, Train Acc: 58.75%
  Val Loss: 0.6304, Val F1: 0.6494
------------------------------------------------------------
  Batch 0/5: Loss = 0.6715
Epoch 13/50:
  Train Loss: 0.6226, Train Acc: 65.62%
  Val Loss: 0.6350, Val F1: 0.6882
------------------------------------------------------------
  Batch 0/5: Loss = 0.6133
Epoch 14/50:
  Train Loss: 0.5881, Train Acc: 73.75%
  Val Loss: 0.6297, Val F1: 0.6882
------------------------------------------------------------
  Batch 0/5: Loss = 0.5934
Epoch 15/50:
  Train Loss: 0.5926, Train Acc: 69.38%
  Val Loss: 0.6459, Val F1: 0.7073
------------------------------------------------------------
  Batch 0/5: Loss = 0.5691
Epoch 16/50:
  Train Loss: 0.5636, Train Acc: 74.38%
  Val Loss: 0.6333, Val F1: 0.6882
------------------------------------------------------------
  Batch 0/5: Loss = 0.5567
Epoch 17/50:
  Train Loss: 0.5861, Train Acc: 72.50%
  Val Loss: 0.6193, Val F1: 0.7200
------------------------------------------------------------
  Batch 0/5: Loss = 0.5041
Epoch 18/50:
  Train Loss: 0.5679, Train Acc: 73.75%
  Val Loss: 0.6244, Val F1: 0.6882
------------------------------------------------------------
  Batch 0/5: Loss = 0.5628
Epoch 19/50:
  Train Loss: 0.5737, Train Acc: 78.75%
  Val Loss: 0.6282, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.6829
Epoch 20/50:
  Train Loss: 0.5848, Train Acc: 73.12%
  Val Loss: 0.6261, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.4741
Epoch 21/50:
  Train Loss: 0.5601, Train Acc: 72.50%
  Val Loss: 0.6239, Val F1: 0.7143
------------------------------------------------------------
  Batch 0/5: Loss = 0.5017
Epoch 22/50:
  Train Loss: 0.5804, Train Acc: 74.38%
  Val Loss: 0.6353, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.6342
Epoch 23/50:
  Train Loss: 0.5844, Train Acc: 71.25%
  Val Loss: 0.6398, Val F1: 0.6500
------------------------------------------------------------
  Batch 0/5: Loss = 0.5886
Epoch 24/50:
  Train Loss: 0.5419, Train Acc: 75.00%
  Val Loss: 0.6531, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.4552
Epoch 25/50:
  Train Loss: 0.5385, Train Acc: 81.25%
  Val Loss: 0.6631, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.5602
Epoch 26/50:
  Train Loss: 0.5112, Train Acc: 77.50%
  Val Loss: 0.6236, Val F1: 0.7357
------------------------------------------------------------
  Batch 0/5: Loss = 0.6866
Epoch 27/50:
  Train Loss: 0.5360, Train Acc: 71.88%
  Val Loss: 0.6440, Val F1: 0.6182
------------------------------------------------------------
  Batch 0/5: Loss = 0.5339
Epoch 28/50:
  Train Loss: 0.5077, Train Acc: 75.00%
  Val Loss: 0.6533, Val F1: 0.6182
------------------------------------------------------------
  Batch 0/5: Loss = 0.3298
Epoch 29/50:
  Train Loss: 0.4982, Train Acc: 76.88%
  Val Loss: 0.6692, Val F1: 0.6362
------------------------------------------------------------
  Batch 0/5: Loss = 0.5752
Epoch 30/50:
  Train Loss: 0.4797, Train Acc: 81.25%
  Val Loss: 0.6657, Val F1: 0.6362
------------------------------------------------------------
  Batch 0/5: Loss = 0.4182
Epoch 31/50:
  Train Loss: 0.5062, Train Acc: 76.88%
  Val Loss: 0.6592, Val F1: 0.6500
------------------------------------------------------------
  Batch 0/5: Loss = 0.3920
Epoch 32/50:
  Train Loss: 0.5009, Train Acc: 77.50%
  Val Loss: 0.6983, Val F1: 0.6182
------------------------------------------------------------
  Batch 0/5: Loss = 0.4662
Epoch 33/50:
  Train Loss: 0.5055, Train Acc: 72.50%
  Val Loss: 0.6798, Val F1: 0.6927
------------------------------------------------------------
  Batch 0/5: Loss = 0.4901
Epoch 34/50:
  Train Loss: 0.4737, Train Acc: 82.50%
  Val Loss: 0.8020, Val F1: 0.6897
------------------------------------------------------------
  Batch 0/5: Loss = 0.5204
Epoch 35/50:
  Train Loss: 0.4561, Train Acc: 86.88%
  Val Loss: 0.6284, Val F1: 0.6599
------------------------------------------------------------
  Batch 0/5: Loss = 0.4539
Epoch 36/50:
  Train Loss: 0.4787, Train Acc: 73.12%
  Val Loss: 0.6065, Val F1: 0.7650
  ‚úÖ New best model saved: F1 = 0.7650
------------------------------------------------------------
  Batch 0/5: Loss = 0.4163
Epoch 37/50:
  Train Loss: 0.4636, Train Acc: 75.62%
  Val Loss: 0.7419, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.3938
Epoch 38/50:
  Train Loss: 0.4603, Train Acc: 86.25%
  Val Loss: 0.7885, Val F1: 0.6897
------------------------------------------------------------
  Batch 0/5: Loss = 0.5240
Epoch 39/50:
  Train Loss: 0.4403, Train Acc: 86.25%
  Val Loss: 0.7578, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.3680
Epoch 40/50:
  Train Loss: 0.4412, Train Acc: 85.00%
  Val Loss: 0.7452, Val F1: 0.6541
------------------------------------------------------------
  Batch 0/5: Loss = 0.4397
Epoch 41/50:
  Train Loss: 0.4413, Train Acc: 77.50%
  Val Loss: 0.6509, Val F1: 0.6800
------------------------------------------------------------
  Batch 0/5: Loss = 0.5367
Epoch 42/50:
  Train Loss: 0.4577, Train Acc: 83.75%
  Val Loss: 0.6881, Val F1: 0.6362
------------------------------------------------------------
  Batch 0/5: Loss = 0.4185
Epoch 43/50:
  Train Loss: 0.4153, Train Acc: 84.38%
  Val Loss: 0.6446, Val F1: 0.6500
------------------------------------------------------------
  Batch 0/5: Loss = 0.3742
Epoch 44/50:
  Train Loss: 0.4018, Train Acc: 83.12%
  Val Loss: 0.7589, Val F1: 0.6362
------------------------------------------------------------
  Batch 0/5: Loss = 0.4555
Epoch 45/50:
  Train Loss: 0.4161, Train Acc: 83.75%
  Val Loss: 0.7679, Val F1: 0.7292
------------------------------------------------------------
  Batch 0/5: Loss = 0.2747
Epoch 46/50:
  Train Loss: 0.4168, Train Acc: 83.12%
  Val Loss: 0.8004, Val F1: 0.6719
------------------------------------------------------------
  Batch 0/5: Loss = 0.3555
Epoch 47/50:
  Train Loss: 0.3917, Train Acc: 90.00%
  Val Loss: 0.6526, Val F1: 0.6691
------------------------------------------------------------
  Batch 0/5: Loss = 0.5238
Epoch 48/50:
  Train Loss: 0.3630, Train Acc: 85.62%
  Val Loss: 0.6234, Val F1: 0.7292
------------------------------------------------------------
  Batch 0/5: Loss = 0.2853
Epoch 49/50:
  Train Loss: 0.3793, Train Acc: 85.00%
  Val Loss: 0.6441, Val F1: 0.7292
------------------------------------------------------------
  Batch 0/5: Loss = 0.4114
Epoch 50/50:
  Train Loss: 0.3470, Train Acc: 86.25%
  Val Loss: 0.6685, Val F1: 0.6691
------------------------------------------------------------

üéØ FINAL EVALUATION ON REAL APT DATA
============================================================
üèÜ BREAKTHROUGH RESULTS ON REAL APT DATA
=================================================================
Final F1-Score: 0.7650 (76.5%)
üìä STRONG PROGRESS: Significant improvement on real data!

Detailed Performance Analysis:
              precision    recall  f1-score   support

      Benign      0.917     0.733     0.815        30
      Attack      0.500     0.800     0.615        10

    accuracy                          0.750        40
   macro avg      0.708     0.767     0.715        40
weighted avg      0.812     0.750     0.765        40


üéØ APT Attack Detection Performance:
   Attack Precision: 0.500 (50.0%)
   Attack Recall: 0.800 (80.0%)
   Attack F1-Score: 0.615
üîç HIGH RECALL: Good attack detection, may need precision tuning

----------------------------------------

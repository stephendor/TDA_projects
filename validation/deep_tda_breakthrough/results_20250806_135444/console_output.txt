Validation Console Output - deep_tda_breakthrough
Timestamp: 20250806_135444
Random Seed: 42
================================================================================

[2025-08-06T13:59:16.847847]
STDOUT:
üöÄ DEEP TDA BREAKTHROUGH VALIDATION
======================================================================
Revolutionary approach: Differentiable topology + Persistent attention
Target: 90%+ F1-score performance
Method: TDA-native deep learning (not TDA‚Üítraditional ML)
======================================================================

üìä DATA PREPARATION
üîß PREPARING DEEP TDA TRAINING DATA
--------------------------------------------------
Generating 1000 sophisticated APT sequences...
Sequence length: 50, Features: 5
‚úÖ Generated 1000 sequences
Attack rate: 50.0%
Sequence shape: (1000, 50, 5)
Data shape: torch.Size([1000, 50, 5]), Labels: torch.Size([1000])
Train: 800, Test: 200

üß† DEEP TDA MODEL INITIALIZATION
Model parameters: 5,262,983
Architecture: Differentiable PH + Persistent Attention + Transformer

üöÄ TRAINING PHASE
üöÄ TRAINING DEEP TDA MODEL
----------------------------------------
Training on: cpu
  Batch 0/25: Loss = 0.7221
  Batch 10/25: Loss = 0.2323
  Batch 20/25: Loss = 0.0331
Epoch 1/30:
  Train Loss: 0.2599, Train Acc: 91.00%
  Val Loss: 0.0175, Val F1: 1.0000
  Learning Rate: 0.000098
  ‚úÖ New best model saved: F1 = 1.0000
--------------------------------------------------
  Batch 0/25: Loss = 0.0189
  Batch 10/25: Loss = 0.0097
  Batch 20/25: Loss = 0.0077
Epoch 2/30:
  Train Loss: 0.0127, Train Acc: 99.88%
  Val Loss: 0.0182, Val F1: 0.9900
  Learning Rate: 0.000091
--------------------------------------------------
  Batch 0/25: Loss = 0.0086
  Batch 10/25: Loss = 0.0039
  Batch 20/25: Loss = 0.0028
Epoch 3/30:
  Train Loss: 0.0042, Train Acc: 100.00%
  Val Loss: 0.0070, Val F1: 0.9950
  Learning Rate: 0.000080
--------------------------------------------------
  Batch 0/25: Loss = 0.0026
  Batch 10/25: Loss = 0.0020
  Batch 20/25: Loss = 0.0018
Epoch 4/30:
  Train Loss: 0.0053, Train Acc: 99.88%
  Val Loss: 0.0017, Val F1: 1.0000
  Learning Rate: 0.000066
--------------------------------------------------
  Batch 0/25: Loss = 0.0417
  Batch 10/25: Loss = 0.0012
  Batch 20/25: Loss = 0.0023
Epoch 5/30:
  Train Loss: 0.0112, Train Acc: 99.50%
  Val Loss: 0.0013, Val F1: 1.0000
  Learning Rate: 0.000051
--------------------------------------------------
  Batch 0/25: Loss = 0.0016
  Batch 10/25: Loss = 0.0012
  Batch 20/25: Loss = 0.0014
Epoch 6/30:
  Train Loss: 0.0012, Train Acc: 100.00%
  Val Loss: 0.0008, Val F1: 1.0000
  Learning Rate: 0.000035
--------------------------------------------------
  Batch 0/25: Loss = 0.0010
  Batch 10/25: Loss = 0.0009
  Batch 20/25: Loss = 0.0012
Epoch 7/30:
  Train Loss: 0.0010, Train Acc: 100.00%
  Val Loss: 0.0007, Val F1: 1.0000
  Learning Rate: 0.000021
--------------------------------------------------
  Batch 0/25: Loss = 0.0009
  Batch 10/25: Loss = 0.0007
  Batch 20/25: Loss = 0.0009
Epoch 8/30:
  Train Loss: 0.0009, Train Acc: 100.00%
  Val Loss: 0.0006, Val F1: 1.0000
  Learning Rate: 0.000010
--------------------------------------------------
  Batch 0/25: Loss = 0.0008
  Batch 10/25: Loss = 0.0009
  Batch 20/25: Loss = 0.0011
Epoch 9/30:
  Train Loss: 0.0008, Train Acc: 100.00%
  Val Loss: 0.0006, Val F1: 1.0000
  Learning Rate: 0.000003
--------------------------------------------------
  Batch 0/25: Loss = 0.0007
  Batch 10/25: Loss = 0.0006
  Batch 20/25: Loss = 0.0007
Epoch 10/30:
  Train Loss: 0.0008, Train Acc: 100.00%
  Val Loss: 0.0006, Val F1: 1.0000
  Learning Rate: 0.000100
--------------------------------------------------
  Batch 0/25: Loss = 0.0008
  Batch 10/25: Loss = 0.0007
  Batch 20/25: Loss = 0.0005
Epoch 11/30:
  Train Loss: 0.0006, Train Acc: 100.00%
  Val Loss: 0.0004, Val F1: 1.0000
  Learning Rate: 0.000098
--------------------------------------------------
  Batch 0/25: Loss = 0.0007
  Batch 10/25: Loss = 0.0007
  Batch 20/25: Loss = 0.0004
Epoch 12/30:
  Train Loss: 0.0005, Train Acc: 100.00%
  Val Loss: 0.0003, Val F1: 1.0000
  Learning Rate: 0.000091
--------------------------------------------------
  Batch 0/25: Loss = 0.0004
  Batch 10/25: Loss = 0.0004
  Batch 20/25: Loss = 0.0003
Epoch 13/30:
  Train Loss: 0.0004, Train Acc: 100.00%
  Val Loss: 0.0002, Val F1: 1.0000
  Learning Rate: 0.000080
--------------------------------------------------
  Batch 0/25: Loss = 0.0006
  Batch 10/25: Loss = 0.0003
  Batch 20/25: Loss = 0.0003
Epoch 14/30:
  Train Loss: 0.0003, Train Acc: 100.00%
  Val Loss: 0.0002, Val F1: 1.0000
  Learning Rate: 0.000066
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0003
  Batch 20/25: Loss = 0.0004
Epoch 15/30:
  Train Loss: 0.0003, Train Acc: 100.00%
  Val Loss: 0.0002, Val F1: 1.0000
  Learning Rate: 0.000051
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0002
Epoch 16/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0002, Val F1: 1.0000
  Learning Rate: 0.000035
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0002
Epoch 17/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0002, Val F1: 1.0000
  Learning Rate: 0.000021
--------------------------------------------------
  Batch 0/25: Loss = 0.0003
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0002
Epoch 18/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000010
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0002
Epoch 19/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000003
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0002
Epoch 20/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000100
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0003
  Batch 20/25: Loss = 0.0002
Epoch 21/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000098
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0001
Epoch 22/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000091
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0002
  Batch 20/25: Loss = 0.0001
Epoch 23/30:
  Train Loss: 0.0002, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000080
--------------------------------------------------
  Batch 0/25: Loss = 0.0002
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 24/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000066
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 25/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000051
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 26/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000035
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 27/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000021
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 28/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000010
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 29/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000003
--------------------------------------------------
  Batch 0/25: Loss = 0.0001
  Batch 10/25: Loss = 0.0001
  Batch 20/25: Loss = 0.0001
Epoch 30/30:
  Train Loss: 0.0001, Train Acc: 100.00%
  Val Loss: 0.0001, Val F1: 1.0000
  Learning Rate: 0.000100
--------------------------------------------------
üèÜ Training completed! Best validation F1: 1.0000

üéØ FINAL EVALUATION

üìà BREAKTHROUGH RESULTS
==================================================
Final F1-Score: 1.0000 (100.0%)
üéâ BREAKTHROUGH ACHIEVED: 90%+ TARGET REACHED!

Detailed Performance:
              precision    recall  f1-score   support

           0      1.000     1.000     1.000       100
           1      1.000     1.000     1.000       100

    accuracy                          1.000       200
   macro avg      1.000     1.000     1.000       200
weighted avg      1.000     1.000     1.000       200


----------------------------------------

name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Nightly runs at 02:00 UTC for staircase probes
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      run_staircase:
        description: "Run large staircase probe (slow; use only on demand)"
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

env:
  TDA_ARTIFACT_DIR: /tmp/tda-artifacts

jobs:
  analyze-reference-artifacts:
    name: Analyze Reference Artifacts (1M ÄŒech, gate ON)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Show artifact directory contents
        run: |
          ls -la docs/performance/artifacts/2025-08-14_1m_cech || true

      - name: Run analyzer with gating (require CSV)
        env:
          REQUIRE_CSV: "1"
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts docs/performance/artifacts/2025-08-14_1m_cech \
            --gate --require-csv

      - name: Compact analyzer summary
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = "docs/performance/artifacts/2025-08-14_1m_cech"
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          parents=[p for p in files if "baseline" not in os.path.basename(p)]
          baselines=[p for p in files if "baseline" in os.path.basename(p)]
          def summary(tag, d):
            keys=["mode","dm_blocks","dm_edges","simplices","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","build_secs","build_peakMB","pool_total_blocks","pool_free_blocks","pool_fragmentation"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {tag}: {kv}")
          pd = last_json(parents[0]) if parents else {}
          bd = last_json(baselines[0]) if baselines else {}
          if pd: summary("parent", pd)
          if bd: summary("baseline", bd)
          if pd and bd:
            for f in ["dm_edges","simplices","dm_blocks","dm_peakMB","rss_peakMB"]:
              try:
                av=pd.get(f); bv=bd.get(f)
                if av is not None and bv is not None:
                  print(f"[summary] delta {f} = {av - bv}")
              except Exception:
                pass
          print("[summary] files:", ", ".join(os.path.basename(x) for x in files))
          PY

      - name: Upload reference artifacts (for PR visibility)
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: reference-artifacts-1m-cech
          path: docs/performance/artifacts/2025-08-14_1m_cech

  cpp-tests:
    name: C++ Build & Streaming Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build
        run: cmake --build build/release --config Release -- -j"$(nproc)"

      - name: Run targeted C++ tests (PerfBaselineJSONL + PerfMonotonicity + VR tests)
        run: |
          ctest --test-dir build/release -R "(PerfBaselineJSONL|PerfMonotonicity|StreamingVRParity|VRTelemetryPresence|VRAdjHistPresence|ManifestPresence)" --output-on-failure --timeout 180

      - name: List JSONL metrics (info only)
        if: always()
        run: |
          echo "Scanning $TDA_ARTIFACT_DIR for JSONL outputs..." || true
          ls -la "$TDA_ARTIFACT_DIR" || true
          echo "Sample telemetry lines (if present):" || true
          grep -E '"(mode|dm_blocks|dm_edges|simplices|softcap_overshoot|dm_peakMB|rss_peakMB)"' -n "$TDA_ARTIFACT_DIR"/*.jsonl || true

      - name: Upload streaming test artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-streaming-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

      - name: Gate artifacts with analyzer (overshoot==0, memory fields present)
        if: always()
        run: |
          if ls "$TDA_ARTIFACT_DIR"/*.jsonl >/dev/null 2>&1; then
            echo "Found JSONL artifacts; running analyzer gate (no CSV required for unit tests)."
            python3 scripts/analyze_performance_logs.py --artifacts "$TDA_ARTIFACT_DIR" --gate
          else
            echo "No JSONL artifacts present in $TDA_ARTIFACT_DIR; skipping analyzer gate."
          fi

  cpp-perf-probe:
    name: C++ Perf Probe (adjacency hist + telemetry)
    runs-on: ubuntu-latest
    needs: cpp-tests
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run Phase 1 validation script (end-to-end)
        run: |
          chmod +x scripts/run_performance_validation.sh
          scripts/run_performance_validation.sh \
            --harness build/release/tests/cpp/test_streaming_cech_perf \
            --artifacts "$TDA_ARTIFACT_DIR"

      - name: Quick overshoot/memory check (non-blocking)
        if: always()
        run: |
          echo "Telemetry summary:" || true
          grep -E 'softcap_overshoot|dm_peakMB|rss_peakMB' -n "$TDA_ARTIFACT_DIR"/*.jsonl || true

      - name: Analyze perf probe artifacts (gate + require CSV + recompute-gate)
        env:
          RECOMPUTE_GATE: "1"
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --gate --require-csv --recompute-gate

      - name: Compact analyzer summary
        if: always()
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = os.environ.get("TDA_ARTIFACT_DIR","/tmp/tda-artifacts")
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          parents=[p for p in files if "baseline" not in os.path.basename(p)]
          baselines=[p for p in files if "baseline" in os.path.basename(p)]
          def summary(tag, d):
            keys=["mode","dm_blocks","dm_edges","simplices","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","build_secs","build_peakMB","pool_total_blocks","pool_free_blocks","pool_fragmentation"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {tag}: {kv}")
          pd = last_json(parents[0]) if parents else {}
          bd = last_json(baselines[0]) if baselines else {}
          if pd: summary("parent", pd)
          if bd: summary("baseline", bd)
          if pd and bd:
            for f in ["dm_edges","simplices","dm_blocks","dm_peakMB","rss_peakMB"]:
              try:
                av=pd.get(f); bv=bd.get(f)
                if av is not None and bv is not None:
                  print(f"[summary] delta {f} = {av - bv}")
              except Exception:
                pass
          print("[summary] files:", ", ".join(os.path.basename(x) for x in files))
          PY

      - name: Upload perf probe artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-perf-probe-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

  cpp-dm-only-probe:
    name: C++ DM-only Probe (200k, tight timeout)
    runs-on: ubuntu-latest
    needs: cpp-tests
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run 200k DM-only probe (serial threshold, soft cap)
        run: |
          build/release/tests/cpp/test_streaming_cech_perf \
            --dm-only --n 200000 --d 3 --radius 0.5 --block 256 \
            --soft-knn-cap 16 --parallel-threshold 0 --time-limit 60 \
            --json "$TDA_ARTIFACT_DIR/sdm_200k.jsonl"

      - name: Analyze DM-only artifacts (gate overshoot==0 + memory fields + recompute-gate)
        env:
          RECOMPUTE_GATE: "1"
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --gate --recompute-gate

      - name: Compact analyzer summary
        if: always()
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = os.environ.get("TDA_ARTIFACT_DIR","/tmp/tda-artifacts")
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          for p in files:
            d=last_json(p)
            keys=["mode","dm_blocks","dm_edges","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","pool_total_blocks","pool_free_blocks","pool_fragmentation"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {os.path.basename(p)}: {kv}")
          PY

      - name: Upload DM-only probe artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-dm-only-200k-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

  cpp-accuracy-check:
    name: C++ Accuracy Check (small-n exact vs soft-cap)
    runs-on: ubuntu-latest
    needs: cpp-tests
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run accuracy check (N=10000, K=8,16,32)
        run: |
          chmod +x scripts/run_accuracy_check.sh
          scripts/run_accuracy_check.sh \
            --harness build/release/tests/cpp/test_streaming_cech_perf \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --n 10000 --d 8 --radius 0.5 --maxDim 1 --klist "8,16,32"

      - name: Upload accuracy artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-accuracy-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

      - name: Analyze accuracy report (gated)
        if: always()
        continue-on-error: true
        run: |
          echo "Running accuracy analysis in warn-only mode (does not fail CI)."
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --accuracy-edges-pct-threshold 5.0 \
            --accuracy-h1-pct-threshold 5.0 \
            --accuracy-gate --gate || echo "Accuracy thresholds exceeded (warning only)."

  cpp-staircase:
    name: C++ Staircase Probe (200K on-demand)
    runs-on: ubuntu-latest
    needs: cpp-tests
    timeout-minutes: 25
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.run_staircase == 'true' }}
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run staircase probe (n=200000)
        run: |
          chmod +x scripts/run_performance_validation.sh
          scripts/run_performance_validation.sh \
            --harness build/release/tests/cpp/test_streaming_cech_perf \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --staircase "200000"

      - name: Upload staircase artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-staircase-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}
  # Optional: enable accuracy gating if reports are produced in staircase context
  # - name: Accuracy gate (optional)
  #   if: always()
  #   run: |
  #     python3 scripts/analyze_performance_logs.py \
  #       --artifacts "$TDA_ARTIFACT_DIR" \
  #       --accuracy-edges-pct-threshold 5.0 \
  #       --accuracy-h1-pct-threshold 5.0 \
  #       --accuracy-gate --gate

  cpp-staircase-nightly:
    name: C++ Staircase Probes (nightly scheduled)
    if: ${{ github.event_name == 'schedule' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        nsize: [200000, 500000, 1000000]
    timeout-minutes: 240
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run staircase probe (n=${{ matrix.nsize }})
        run: |
          chmod +x scripts/run_performance_validation.sh
          scripts/run_performance_validation.sh \
            --harness build/release/tests/cpp/test_streaming_cech_perf \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --staircase "${{ matrix.nsize }}"

      - name: Analyze staircase artifacts (gate + require CSV)
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --gate --require-csv

      - name: Compact analyzer summary
        if: always()
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = os.environ.get("TDA_ARTIFACT_DIR","/tmp/tda-artifacts")
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          parents=[p for p in files if "baseline" not in os.path.basename(p)]
          baselines=[p for p in files if "baseline" in os.path.basename(p)]
          def summary(tag, d):
            keys=["mode","dm_blocks","dm_edges","simplices","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","build_secs","build_peakMB","pool_total_blocks","pool_free_blocks","pool_fragmentation"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {tag}: {kv}")
          pd = last_json(parents[0]) if parents else {}
          bd = last_json(baselines[0]) if baselines else {}
          if pd: summary("parent", pd)
          if bd: summary("baseline", bd)
          if pd and bd:
            for f in ["dm_edges","simplices","dm_blocks","dm_peakMB","rss_peakMB"]:
              try:
                av=pd.get(f); bv=bd.get(f)
                if av is not None and bv is not None:
                  print(f"[summary] delta {f} = {av - bv}")
              except Exception:
                pass
          print("[summary] files:", ", ".join(os.path.basename(x) for x in files))
          PY

      - name: Upload staircase artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-staircase-nightly-${{ matrix.nsize }}-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

  cpp-vr-perf-probe:
    name: C++ VR Perf Probe (adjacency hist + telemetry)
    runs-on: ubuntu-latest
    needs: cpp-tests
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run VR perf probe (parent+baseline histograms)
        run: |
          chmod +x scripts/run_performance_validation.sh
          # Use epsilon analogous to radius; maxDim=1 to keep CI time bounded
          scripts/run_performance_validation.sh \
            --harness build/release/tests/cpp/test_streaming_cech_perf \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --n 10000 --d 8 --maxDim 1 --K 16 --radius 0.5
          # Re-run with VR mode at n=10000 (serial threshold), emitting parent and baseline artifacts
          build/release/tests/cpp/test_streaming_cech_perf \
            --mode vr --n 10000 --d 8 --epsilon 0.5 --maxDim 1 \
            --soft-knn-cap 16 --parallel-threshold 0 \
            --adj-hist-csv "$TDA_ARTIFACT_DIR/adj_vr_parent.csv" \
            --baseline-compare 1 --baseline-separate-process 1 \
            --baseline-json-out "$TDA_ARTIFACT_DIR/baseline_vr.jsonl" \
            --adj-hist-csv-baseline "$TDA_ARTIFACT_DIR/adj_vr_baseline.csv" \
            --json "$TDA_ARTIFACT_DIR/run_vr.jsonl"

      - name: Analyze VR probe artifacts (gate + require CSV + recompute-gate)
        env:
          RECOMPUTE_GATE: "1"
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --gate --require-csv --recompute-gate

      - name: Compact analyzer summary
        if: always()
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = os.environ.get("TDA_ARTIFACT_DIR","/tmp/tda-artifacts")
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          parents=[p for p in files if "baseline" not in os.path.basename(p)]
          baselines=[p for p in files if "baseline" in os.path.basename(p)]
          for p in files:
            d=last_json(p)
            keys=["mode","dm_blocks","dm_edges","simplices","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","build_secs","build_peakMB","pool_total_blocks","pool_free_blocks","pool_fragmentation"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {os.path.basename(p)}: {kv}")
          if parents and baselines:
            pd = last_json(parents[0]); bd = last_json(baselines[0])
            print("[summary] delta (parent-baseline):")
            for f in ["dm_edges","simplices","dm_blocks","dm_peakMB","rss_peakMB"]:
              try:
                av=pd.get(f); bv=bd.get(f)
                if av is not None and bv is not None:
                  print(f"[summary]  - {f}: {av - bv}")
              except Exception:
                pass
          PY

      - name: Upload VR probe artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-vr-probe-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}

  cpp-vr-nightly:
    name: C++ VR Probe (nightly, small-n)
    if: ${{ github.event_name == 'schedule' }}
    runs-on: ubuntu-latest
    needs: cpp-tests
    steps:
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build \
            libeigen3-dev libgmp-dev libmpfr-dev libtbb-dev python3

      - name: Prepare artifact directory
        run: mkdir -p "$TDA_ARTIFACT_DIR"

      - name: Configure (Release)
        run: |
          cmake -S . -B build/release \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON \
            -DBUILD_PYTHON=OFF

      - name: Build harness
        run: cmake --build build/release --config Release --target test_streaming_cech_perf -- -j"$(nproc)"

      - name: Run small VR probe (serial threshold)
        run: |
          build/release/tests/cpp/test_streaming_cech_perf \
            --mode vr --n 10000 --d 8 --epsilon 0.5 --maxDim 1 \
            --soft-knn-cap 16 --parallel-threshold 0 \
            --adj-hist-csv "$TDA_ARTIFACT_DIR/adj_vr_nightly.csv" \
            --json "$TDA_ARTIFACT_DIR/run_vr_nightly.jsonl"

      - name: Analyze VR nightly artifacts (gate + require CSV)
        run: |
          python3 scripts/analyze_performance_logs.py \
            --artifacts "$TDA_ARTIFACT_DIR" \
            --gate --require-csv

      - name: Compact analyzer summary
        if: always()
        run: |
          python3 - <<'PY'
          import glob,json,os,sys
          arts = os.environ.get("TDA_ARTIFACT_DIR","/tmp/tda-artifacts")
          files = sorted(glob.glob(os.path.join(arts, "*.jsonl")))
          if not files:
            print("[summary] No JSONL artifacts found.")
            sys.exit(0)
          def last_json(path):
            data=None
            with open(path,'r') as f:
              for line in f:
                line=line.strip()
                if line:
                  try:
                    data=json.loads(line)
                  except Exception:
                    pass
            return data or {}
          def fmt(v):
            return "-" if v is None else str(v)
          for p in files:
            d=last_json(p)
            keys=["mode","dm_blocks","dm_edges","simplices","dm_peakMB","rss_peakMB","softcap_overshoot_sum","softcap_overshoot_max","parallel_threshold","build_secs","build_peakMB"]
            kv=", ".join(f"{k}={fmt(d.get(k))}" for k in keys if k in d)
            print(f"[summary] {os.path.basename(p)}: {kv}")
          PY

      - name: Upload VR nightly artifacts
        if: always()
        uses: actions/upload-artifact@ff15f0306b3f739f7b6fd43fb5d26cd321bd4de5 # v3.2.1
        with:
          name: cpp-vr-nightly-artifacts
          path: ${{ env.TDA_ARTIFACT_DIR }}
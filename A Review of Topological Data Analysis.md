# [cite\_start]A Review of Topological Data Analysis for Cybersecurity [cite: 2]

[cite\_start]**Thomas Davies** [cite: 3]  
The Alan Turing Institute  
[cite\_start]The British Library, London, UK. [cite: 4]  
[cite\_start]tdavies@turing.ac.uk [cite: 4]

## [cite\_start]Abstract [cite: 5]

[cite\_start]In cybersecurity it is often the case that malicious or anomalous activity can only be detected by combining many weak indicators of compromise, any one of which may not raise suspicion when taken alone. [cite: 6] [cite\_start]The path that such indicators take can also be critical. [cite: 7] [cite\_start]This makes the problem of analysing cybersecurity data particularly well suited to Topological Data Analysis (TDA), a field that studies the high level structure of data using techniques from algebraic topology, both for exploratory analysis and as part of a machine learning workflow. [cite: 8] [cite\_start]By introducing TDA and reviewing the work done on its application to cybersecurity, we hope to highlight to researchers a promising new area with strong potential to improve cybersecurity data science. [cite: 9]

## [cite\_start]1 Introduction [cite: 10]

[cite\_start]Topological Data Analysis (TDA) allows practitioners to study the topology of a dataset using mathematical tools that come with strong theoretical guarantees. [cite: 11] [cite\_start]Roughly, the topology of data is its global structure, meaning we can use TDA to analyse the 'shape' of datasets in ways that traditional data analysis methods cannot. [cite: 12] [cite\_start]In cybersecurity, many of the actions that threat actors take are individually not problematic; it is only when you consider the actions together that an issue becomes apparent (Winding, Wright, and Chapple 2006). [cite: 13, 14] [cite\_start]This makes cybersecurity data particularly well-suited to analysis by TDA, as it is capable of spotting anomalous patterns at a global level. [cite: 15]

[cite\_start]The primary techniques in TDA are Mapper and persistent homology. [cite: 16] [cite\_start]Mapper is an algorithm that can embed large high-dimensional datasets into a much smaller graph in a topology-preserving way, enabling its visualisation and analysis. [cite: 17] [cite\_start]Persistent homology produces a persistence diagram: a concise summary of the topology of a dataset which can be vectorised and used as input to other machine learning methods. [cite: 18] [cite\_start]There is an increasing body of work that shows TDA capable of performing at the state of the art on a large number of machine learning tasks. [cite: 19] To give just one example, Zhao et al. (2020) [cite\_start]add persistent homology to graph neural networks to achieve the state of the art on many graph classification tasks. [cite: 20]

[cite\_start]Both strands of TDA have found applications in cybersecurity. [cite: 21] [cite\_start]Vast networks are common in this domain, and Mapper can reduce the size of large datasets in a principled way, allowing human operators to better visualise and understand the data they are working with. [cite: 21, 23] [cite\_start]Indeed, the primary application of Mapper that we see in the literature is to reduce large datasets of network traffic into more interpretable graphs that can be viewed by human analysts. [cite: 24] [cite\_start]Clusters in the mapper graph are shown to correspond to types of anomaly (Coudriau, Lahmadi, and François 2016), and proximity to potential anomalies within the mapper graph can alert analysts to traffic worth further investigation (Bihl et al. 2020). [cite: 25]

[cite\_start]Persistence diagrams have also been used with success on cybersecurity data. [cite: 26] [cite\_start]Winding, Wright, and Chapple (2006) say that 'little information can be gained from analysing individual records, [as] often the presence of intrusion behaviour or other anomalous activity can only be detected by looking at the aggregate behaviour of related records'. [cite: 27] [cite\_start]Persistence diagrams offer the ability to summarise the global behaviour of a large number of records, so their application to cybersecurity is very natural. [cite: 28] [cite\_start]This is demonstrated in the literature, with persistence diagrams being applied to successfully identify anomalies in network logs (Bruillard, Nowak, and Purvine 2016) and, coupled with convolutional neural networks (CNNs), identify IoT devices from encrypted packet data (Collins et al. 2020). [cite: 29] [cite\_start]More broadly, this relates to detecting change points. [cite: 30] [cite\_start]Indeed, there is an active research grant on TDA for Threat Detection which has produced research on detecting change points topologically (Islambekov, Yuvaraj, and Gel 2019). [cite: 30]

[cite\_start]Before we can apply TDA we need to embed cybersecurity data in a way that is compatible with topological tools. [cite: 31] [cite\_start]This can either be by embedding into $\\mathbb{R}^{d}$, or we can apply other tricks to embed directly into simplicial complexes the type of structure required for TDA. [cite: 32] [cite\_start]The choice of embedding has a large influence on the success of TDA, so we review different choices made in the literature. [cite: 33] [cite\_start]These range from general graph embedding techniques to those that are cybersecurity specific. [cite: 34]

[cite\_start]The structure of this review is as follows. [cite: 35] [cite\_start]In Section 2 we give an introduction to Mapper and persistent homology, providing references for the interested reader. [cite: 35] [cite\_start]In Section 3 we summarise techniques to embed cybersecurity data as either vectors or graphs. [cite: 36, 41] [cite\_start]In Sections 4 and 5 we review the literature on Mapper and persistent homology for cybersecurity respectively. [cite: 41] [cite\_start]In Section 6 we summarise research on graph metrics for cybersecurity that are closely tied to TDA. [cite: 42] [cite\_start]We conclude in Section 7, and in Appendix A we list datasets that may be of interest to readers. [cite: 43]

## [cite\_start]2 Overview of TDA [cite: 44]

[cite\_start]Topological Data Analysis can be split into the Mapper algorithm and the persistent homology pipeline. [cite: 45] [cite\_start]Although not at first glance related, they both rely on the Nerve Theorem: a result in algebraic topology that guarantees a certain representation of a space preserves its topology (Hatcher 2000, Corollary 4G.3). [cite: 46] [cite\_start]This theoretical guarantee underpins TDA, allowing representations of data that preserve global structure. [cite: 47] [cite\_start]In the following we give a brief overview of TDA, but for more details see the textbook by Edelsbrunner and Harer (2010) or the lecture notes from Nanda (2021). [cite: 48]

### [cite\_start]Mapper [cite: 49]

[cite\_start]The Mapper algorithm (Singh, Mémoli, and Carlsson 2007) was the first algorithm to take advantage of a topological viewpoint of data. [cite: 50] [cite\_start]It can map complex high-dimensional datasets into lower-dimensional structures most commonly graphs in a topology-preserving way. [cite: 51] [cite\_start]This low-dimensional representation of the data is more interpretable than the data itself, and can be used to highlight areas of interest. [cite: 52] [cite\_start]Figure 1 gives an example of the whole Mapper process that we'd recommend referring to as we describe the algorithm. [cite: 53]

[cite\_start]Given a dataset we split it up into overlapping areas. [cite: 54] [cite\_start]This is most commonly done with hypercubes, but can be done with any function (the domain of the function determines what structure you map onto). [cite: 55] [cite\_start]For the data contained in each hypercube run a clustering algorithm; each cluster is a node in the output of the algorithm. [cite: 56, 57] [cite\_start]When two clusters from different hypercubes share a point from the original data (which will happen, as the hypercubes overlap), add an edge between the nodes in the output of the algorithm. [cite: 58] [cite\_start]In this way you can map large high-dimensional datasets into a graph which the Nerve Theorem guarantees will preserve the structure of the initial dataset. [cite: 59] [cite\_start]The results of Mapper depend heavily on the way you split your data and the clustering algorithm used, but experiments have shown Mapper to be very capable of providing new insight to data with sufficient parameter tuning, particularly when complemented with domain knowledge. [cite: 60] To give some examples, Lum et al. (2013) [cite\_start]gave applications of Mapper to tumours, voting, and player performance in the NBA. [cite: 61] [cite\_start]Nicolau, Levine, and Carlsson (2011) used Mapper to identify a new subtype of breast cancer with high survival rates, a result that was one of the early indications of the efficacy of TDA. [cite: 62]

-----

[cite\_start]**Figure 1:** In Mapper data is split up, clustered, then the resulting cluster centres are connected together based on shared nodes, leading to a graph that summarises the dataset in a topology-preserving way. [cite: 40]

-----

### [cite\_start]Persistent homology [cite: 63]

[cite\_start]In the following we summarise how the persistent homology pipeline works. [cite: 64] [cite\_start]The key takeaway is that we end up with a (potentially vectorised) persistence diagram that concisely summarises the global structure of the inputted data. [cite: 65] [cite\_start]This can be used as-is or fed into a machine learning technique of your choosing for downstream tasks. [cite: 66]

[cite\_start]To compute the persistent homology we need a filtration of simplicial complexes. [cite: 67] [cite\_start]A simplicial complex is a collection of nodes, edges, triangles, and other higher dimensional equivalents, such that every simplex contains each of its constituent simplices (i.e., for any triangle in the complex, the complex also contains its edges and vertices), and the intersection of any two simplices in the complex is also a simplex in the complex. [cite: 68] [cite\_start]A filtration of simplicial complexes is a series of simplicial complexes $K\_{0}$, $K\_{1}$, K2,.. such that $K\_{0}\\subseteq K\_{1}\\subseteq K\_{2}\\subseteq...$ (see Figure 2). [cite: 69] [cite\_start]The parameter e for complex $K\_{\\epsilon}$ is referred to as the time or scale of the filtration. [cite: 70] [cite\_start]We can build simplicial complexes from data in many ways. [cite: 71] [cite\_start]Given a point dataset, a common way is the 6-Vietoris-Rips complex (Vietoris 1927). [cite: 72] [cite\_start]We add k points as a simplex to the complex when they are pairwise within e distance of each other. [cite: 73] [cite\_start]Letting $K\_{\\epsilon}$ be the e-Vietoris-Rips complex gives a filtration of simplicial complexes which we can use to compute the persistent homology. [cite: 74] [cite\_start]We can also create complexes in other ways. [cite: 75] [cite\_start]For example, in cybersecurity we may want to to build complexes from network data, connecting nodes that have had network connections with each other. [cite: 75] [cite\_start]In this case our scale parameter could be the time at which the network connection took place. [cite: 76, 84] [cite\_start]This results in an equally valid filtration which we can use to compute the persistent homology. [cite: 84]

-----

[cite\_start]**Figure 2:** On the left is a Vietoris-Rips filtration, shown with increasing values for E. [cite: 80] [cite\_start]On the right is the persistence diagram of the filtration. [cite: 81] [cite\_start]Each blue point is in the 0-persistence diagram, and represents a connected component. [cite: 82] [cite\_start]The orange point is in the 1-persistence diagram and represents the hole. [cite: 83]

-----

[cite\_start]For each simplicial complex $K\_{\\epsilon}$ we compute the p-homology group. [cite: 85] [cite\_start]This tells us the topology of $K\_{\\epsilon}$ the 0-homology counts the number of connected components, the 1-homology counts the number of holes, the 2-homology counts the number of voids (e.g., the hole inside of a football), and so on (Edelsbrunner, Letscher, and Zomorodian 2000). [cite: 86] [cite\_start]Thus we can use homology groups to describe the topology of $K\_{\\epsilon}$. [cite: 87] [cite\_start]However, we need to decide when computing the homology group which value of e we want to consider. [cite: 88] [cite\_start]In the case of a Vietoris-Rips complex, small values of e will result in disconnected points, whereas large values of e will connect everything. [cite: 89] [cite\_start]The persistence trick circumvents that choice by allowing us to consider every simultaneously. [cite: 90]

[cite\_start]We construct the p-persistent homology group by summing the p-homology groups over all 6. [cite: 91] [cite\_start]This allows us to see how topological features persist throughout the filtration: simplices may enter the filtration at $K\_{i}$ which cause a hole. [cite: 91] [cite\_start]More simplices may enter the filtration, say at $K\_{j}$, that fill the hole. [cite: 92] [cite\_start]In this case, we refer to the birth of the hole as at time i, its death at time j, and we say it persists for $j-i$. [cite: 93] [cite\_start]In this way we can characterise the topological features present throughout the filtration. [cite: 94] [cite\_start]Some features may never die (for example, there will always be at least one connected component), in which case we say the death time is infinity. [cite: 95]

[cite\_start]Birth and death times for topological features offer a good way to visualise the persistent homology of a filtration. [cite: 96] [cite\_start]We can plot a diagram called the persistence diagram, in which the -axis represents birth time, the y-axis represents death time, and each point is a topological feature within the filtration. [cite: 97] [cite\_start]An example is shown in Figure 2, in which the orange point is in the 1-persistence diagram and represents the hole we can see within the filtration. [cite: 98] [cite\_start]The further above the diagonal a point is in the diagram, the longer it persists for, and the more likely it is to represent a topological feature rather than noise. [cite: 99]

[cite\_start]There are distances defined on the space of persistence diagrams (e.g., the Wasserstein distance), but the space of persistence diagrams is not Hilbert. [cite: 100] [cite\_start]Therefore in order to conveniently integrate persistence diagrams into machine learning workflows we must embed them. [cite: 101, 102] [cite\_start]Persistence diagrams can be vectorised by a large number of techniques, but probably most common is persistent images (Chepushtanova et al. 2015). [cite: 102] [cite\_start]This puts a Gaussian on each non-diagonal point of the persistence diagram and integrates the resultant surface over a grid to vectorise the diagram. [cite: 103] [cite\_start]Other common approaches are persistence landscapes (Bubenik et al, 2015) or Betti curves (Rieck, Sadlo, and Leitte 2017), both of which end up with functional embeddings. [cite: 104]

## 3 Embedding cybersecurity data

[cite\_start]Cybersecurity data usually comes in forms that aren't immediately amenable to TDA or, in fact, any machine learning algorithm. [cite: 105] [cite\_start]As such, choosing how to embed the data is an important step in any data science workflow for cybersecurity. [cite: 106] [cite\_start]Much of the data naturally has a graph structure, as many things that we consider live on a network. [cite: 107] [cite\_start]Some researchers choose to embed the data in a way that respects this graph structure, whereas others choose to disregard it; both options have had success in the literature. [cite: 108, 109] [cite\_start]In this section we cover cyber-specific embeddings that both respect and disregard the graph structure, as well as more general graph embedding techniques. [cite: 109]

[cite\_start]In the TDA for cybersecurity literature, we most often see Mapper applied to vectors that are built in a graph-agnostic way, even when the initial data has a graph structure. [cite: 110] [cite\_start]This is unnecessary, as Mapper can be applied directly to graphs (Hajij, Rosen, and Wang 2018), but the tools to do so are less developed. [cite: 111] [cite\_start]In the case of persistent homology, again the majority of papers embed the data in a graph-agnostic way before computing the Vietoris-Rips complex. [cite: 112] [cite\_start]However, some approaches (Collins et al. 2020) use the existing network structure and create their filtration using features in the data, showing that such an approach is feasible. [cite: 113]

### [cite\_start]Graph-agnostic embeddings [cite: 114]

[cite\_start]Winding, Wright, and Chapple (2006) proposed vectorising network log data by summing numeric fields and counting enumerated fields. [cite: 115] [cite\_start]They suggested the following feature vectors: [cite: 116]

  * [cite\_start]source IP, number of destination IP addresses; [cite: 117]
  * [cite\_start]destination IP, number of failed access attempts; [cite: 120]
  * [cite\_start]source IP, destination IP; [cite: 120]
  * [cite\_start]destination perspective vector (consisting of destination IP, number of successful accesses, number of failed accesses, count of destination points, number of inbound bytes, number of outbound bytes). [cite: 121, 122]

[cite\_start]This technique has been used in several pieces of anomaly detection research (Jakub and Branišová 2015; Bihl et al. 2020). [cite: 123] [cite\_start]Bruillard, Nowak, and Purvine (2016) proposed embedding NetFlow data into feature vectors that summarise either the cumulative number of packets sent or received by an IP of interest, the total number of packets sent or received by each IP, or the total number of packets sent or received by each IP to an IP of interest. [cite: 124] [cite\_start]These vectors are created over a window of a given length that advances over the whole dataset. [cite: 125] [cite\_start]The length of window and increment time are parameters that the authors vary. [cite: 126] [cite\_start]They show that the choice of window length and increment time can affect the performance on downstream tasks. [cite: 127]

-----

[cite\_start]**Figure 3:** Mapper applied to firewall logs. [cite: 118] [cite\_start]Nodes in close proximity to those flagged as potentially anomalous could be worth further investigation. [cite: 118] Reproduced with permission from Bihl et al. (2020)[cite\_start]. [cite: 119]

-----

### [cite\_start]Event data as graphs [cite: 128]

Aksoy et al. (2019) [cite\_start]considered a sliding window of 60 seconds that advanced 20 seconds at a time over event logs. [cite: 129] [cite\_start]For the events in each window they construct a graph - the specific graphs they consider are listed below. [cite: 130]

  * [cite\_start]**Authentication graphs** are unweighted graphs built from authentication data that has source user/destination user as edges. [cite: 131]
  * [cite\_start]**Authentication failure graphs** are as above, but restricted to failed authentication events. [cite: 132]
  * [cite\_start]**Process graphs** are built from start/stop records of processes. [cite: 133] [cite\_start]The graph consists of edges between computers and process names. [cite: 134]
  * [cite\_start]**DNS graphs** are built from DNS lookup events with edges from source computer to resolved computer. [cite: 135]
  * [cite\_start]**Flow graphs** are built from the records of every network flow event. [cite: 136] [cite\_start]The edges are between the source computer and the destination computer. [cite: 137]

Collins et al. (2020) [cite\_start]used encrypted packet data to build a filtration. [cite: 138] [cite\_start]They picked a device of interest and connected it to the last n devices that it exchanged packets with. [cite: 139] [cite\_start]They induced a filtration by the inter-packet arrival time, a metric that has previously been shown to contain discriminative information when the traffic is encrypted. [cite: 140] [cite\_start]Once all edges of a 2-simplex were present, they added the 2-simplex (Figure 6a). [cite: 141] [cite\_start]By doing so they avoided computing the expensive Vietoris-Rips complex, and instead used the natural structure of the data and a relevant feature to induce a filtration. [cite: 142]

### [cite\_start]Graph embeddings [cite: 143]

[cite\_start]Given the prevalence of graph-structured datasets in cybersecurity, we offer a brief review of techniques to embed graphs into $\\mathbb{R}^{d}$. [cite: 144]

**Skip-gram based models.** Skip-gram was introduced by Mikolov et al. (2013a,b) [cite\_start]to improve word embeddings for NLP. [cite: 145] [cite\_start]Given a word from a sentence, the idea of skip-gram is to maximise the average log probability that your model can predict the next word. [cite: 146] [cite\_start]Node2Vec (Grover and Leskovec 2016) and LINE (Tang et al. 2015) adapted this for graph-structured data by maximising the probability that, given a node v, you can predict a node in the neighbourhood of v. [cite: 147] [cite\_start]Since the neighbourhoods over several hops can grow prohibitively large, they are sampled by random walk, with different adaptations using different sampling techniques. [cite: 147]

[cite\_start]**Graph neural networks.** GNNs learn to aggregate feature vectors across nodes by combining features with those of their neighbours. [cite: 148] [cite\_start]Initially graph neural networks were classified as either spectral - aggregating neighbours in the spectral domain or spatial aggregating otherwise. [cite: 149] [cite\_start]However, true spectral filters require an expensive computation of the Fourier basis, so in general this was approximated, resulting in networks that were essentially spatial. [cite: 150] [cite\_start]As such, GNNs are now categorised as either convolutional, attentional, or message-passing. [cite: 151] [cite\_start]The difference lies in how information from the neighbourhood is aggregated. [cite: 152] [cite\_start]Convolutional networks aggregate with a linear sum using fixed edge weights as coefficients for a function of the node feature vectors (Kipf and Welling 2017). [cite: 153] [cite\_start]Attentional networks learn an attention function on edges that acts as the coefficient (Monti et al. 2017). [cite: 154] [cite\_start]Message-passing networks are the most general, learning one function on adjacent feature vectors that decides now to aggregate them (Battaglia et al. 2016). [cite: 155]

[cite\_start]**Embedding large graphs.** The techniques we have discussed so far cannot scale to large graphs, which is problematic as cybersecurity data can be very large. [cite: 156] [cite\_start]GraphSage (Hamilton, Ying, and Leskovec 2017) samples neighbours rather than fully computing the neighbourhood, and mini-batches, i.e., only updates the gradients for a limited number of nodes at a time. [cite: 157] [cite\_start]By doing so it enables large graphs (\>100,000 nodes) to be processed with GNNs. [cite: 158] [cite\_start]ClusterGCN (Chiang et al. 2019) and GraphSAINT (Zeng et al. 2020) speed up GraphSage by removing some redundant computations. [cite: 159] [cite\_start]Facebook and Twitter have both also released methods for prcessing very large graphs. [cite: 169] [cite\_start]Twitter restricted large GNNs to a single layer (Frasca et al. 2020) enabling huge computational speed-ups with much more parallelisation. [cite: 170] [cite\_start]However, the authors of this work suggest in a blog post that it is best used as as a fast benchmark for other models, so the lack of depth does ultimately seem to effect the performance of the network. [cite: 171] [cite\_start]Facebook proposed Pytorch Big Graph (Lerer et al. 2019). [cite: 172] [cite\_start]PBG works on multi-relational graphs: graphs where you can have different types of edges. [cite: 172] [cite\_start]It introduces several tricks to allow multi-relational GNNs to work on graphs with billions of nodes and trillions of edges. [cite: 173]

## [cite\_start]4 Mapper for cybersecurity [cite: 174]

[cite\_start]In this section we review the literature on applications of Mapper to cybersecurity, splitting it by application domain. [cite: 175] [cite\_start]We find that it is most often used as an investigative and visualisation tool, although in some cases can provide quantitative information. [cite: 176]

-----

[cite\_start]**Figure 4:** Data collected by a network telescope is shown on the left. [cite: 163] [cite\_start]In the middle diagram is the Mapper graph of the data. [cite: 164] [cite\_start]Manual examination of the connected components showed that the large green dot is traffic attempting to exploit a known router vulnerability, the red component is traffic trying to access Telnet or SSH, the orange component is a sparse port scan from a single address, and the yellow component is a randomised scan and some noise. [cite: 165] [cite\_start]On the right the initial data is coloured according to the Mapper graph. [cite: 166] [cite\_start]We can see that the components are disorderly within the data, despite Mapper pulling out distinct attack types. [cite: 167] [cite\_start]Reproduced with permission from Coudriau, Lahmadi, and François (2016). [cite: 168]

-----

**Anomaly detection.** Bihl et al. (2020) [cite\_start]applied Mapper to firewall logs from an enterprise-level organisation. [cite: 177] [cite\_start]The authors used a graph agnostic embedding technique developed by Winding, Wright, and Chapple (2006) that we cover in Section 3 (counting categorical fields and summing numerical fields). [cite: 178] After embedding the logs they computed the histogram matrix (HMAT) introduced by Gutierrez et al. (2018)[cite\_start]. [cite: 179] [cite\_start]This was intended to provide a way for analysts to visualise logs that may be anomalous over some block of time. [cite: 180] Bihl et al. (2020) [cite\_start]associated an HMAT with each node in the mapper graph, then anomalous nodes in the Mapper graph can flag to analysts that adjacent nodes may also be worth further investigation (Figure 3). [cite: 181, 184] [cite\_start]However, this claim goes relatively untested, and the tool is framed more as an exploratory technique than something that can reliably find anomalous events. [cite: 184] [cite\_start]Rizzo (2020) similarly used Mapper to plot intrusion detection system data. [cite: 185]

[cite\_start]**Network telecopes.** Ranges of IPs with no active domains can be used to analyse traffic not directed towards real hosts. [cite: 186] [cite\_start]Since devices listening to this traffic are not real, any traffic to them is likely to be malicious (Fachkha and Debbabi 2015). [cite: 187] [cite\_start]In the literature such traffic is called internet background radiation (IBR) and the listening devices are referred to as network telescopes. [cite: 188] [cite\_start]Coudriau, Lahmadi, and François (2016) used Mapper on data from a network telescope to find port scans and DDoS attacks, outperforming traditional clustering algorithms when attacks don't cover the full range of possible ports or IPs. [cite: 189] [cite\_start]Of the many port scans identified by Mapper in the data, only a small proportion were found by the ruleset of the intrusion detection system Suricata, demonstrating that Mapper can outperform standard industry techniques in some cases. [cite: 190] [cite\_start]Mapper is also able to distinguish types of attack from complex data: examining the connected components of the Mapper graph of source/destination IP/port data from a network telescope showed that most components represent a distinct attack, including the attempted exploitation of a known router vulnerability (Figure 4). [cite: 191] [cite\_start]Narita (2021) also computed the Mapper graphs of network telescope data, but instead focused on describing the resultant graphs without attempting to link them to different attack types. [cite: 192]

[cite\_start]**Tor traffic detection.** If encrypted Tor traffic is detected as it passes through a network then connections can be immediately shut down and investigated. [cite: 193] [cite\_start]van Veen (2018) investigated Mapper as an unsupervised technique for visualising and classifying Tor traffic within a network. [cite: 194] [cite\_start]There is some success, with qualitative observations that Tor traffic tends to be on the extremes of the Mapper graph. [cite: 195, 196]

**Ransomware payments.** Akcora et al. (2020) [cite\_start]computed a Mapper graph from Bitcoin transaction data. [cite: 197] [cite\_start]If a certain proportion of addresses that are within a node of the Mapper graph are known to receive ransomware payments then the remaining addresses have their risk scores increased. [cite: 198] [cite\_start]Repeating over the entire map and thresholding the acceptable risk gave a list of suspicious Bitcoin addresses. [cite: 199] [cite\_start]This approach outperformed DBSCAN and XGBoost at detecting suspicious addresses. [cite: 200]

[cite\_start]**Attack graphs.** An attack on a computer network consists of several different stages, which are categorised by the Mitre ATT\&CK® framework as reconnaissance, delivery, exploitation, operation, data collection, and exfiltration. [cite: 201] [cite\_start]Such a sequence of actions naturally admits a graph structure, referred to as an attack graph. [cite: 202] This graph is susceptible to analysis with topological techniques, which was the focus of work by Navarro et al. (2018)[cite\_start]. [cite: 203] [cite\_start]They focused on context, attack patterns, and events, which combine to create an attack graph. [cite: 204] [cite\_start]They applied mapper to this attack graph in the hope that the reduced graph is able to be analysed by humans who can find repeated structures across attacks. [cite: 205]

## 5 Persistence for cybersecurity

[cite\_start]Persistence diagrams capture specific topological information about data which can be used independently for data analysis, or vectorised and fed into machine learning methods for further analysis and prediction. [cite: 206] [cite\_start]We see in this section that this can be used for anomaly detection and classification in far more quantitative ways than Mapper. [cite: 207]

-----

[cite\_start]**Figure 5:** The spike in topological dissimilarity indicates a predicted anomaly. [cite: 233] [cite\_start]In fact, this was a port scan. [cite: 233] [cite\_start]Reproduced with permission from Bruillard, Nowak, and Purvine (2016). [cite: 234]

-----

[cite\_start]**Anomaly detection.** Bruillard, Nowak, and Purvine (2016) used the distance between persistence diagrams computed from NetFlow data to detect anomalies. [cite: 208] [cite\_start]Vectorising the NetFlow data with a sliding window over the data counting packets (as described in Section 3), the authors computed a baseline persistence diagram from a collection of feature vectors B. [cite: 209] [cite\_start]For every other vector , they computed the Wasserstein distance between the persistence diagrams of B and $B\\cup{x}$. [cite: 209] [cite\_start]The larger the distance, the more topologically different the points are, and they found that spikes in topological dissimilarity are indicative of anomalies (Figure 5). [cite: 210]

[cite\_start]**Activity prediction.** Gabdrakhmanova (2018) summarised persistence diagrams with the Euler characteristic. [cite: 211] [cite\_start]Specifically, this is the alternating sum of the Betti numbers, which are approximated by the total persistence of the points in persistence diagrams, increasing by dimension. [cite: 212] [cite\_start]Given the levels of recent activity at a network switch (say, at an ISP), they wished to predict the future levels of activity. [cite: 213] [cite\_start]They have bits/minute data for 7 days. [cite: 214] [cite\_start]They split the data into two hour chunks and computed a persistence diagram for each two hour period. [cite: 214] [cite\_start]From that, they estimated the Euler characteristic of that period, as described above. [cite: 215] [cite\_start]They inputted the Euler characteristics into a neural network to predict future activity, but did not evaluate the success of their approach. [cite: 216]

**IoT device fingerprinting.** Postol et al. (2019) [cite\_start]showed that persistent homology works particularly well for classifying incomplete and noisy data from internet of things (IoT) devices on networks. [cite: 217, 235] [cite\_start]They computed the persistence diagrams of embedded IoT network traffic, and used feature selection then logistic regression on functional embeddings of the diagrams to classify types of IoT devices (differentiating cameras, sensors, and multipurpose devices like tablets). [cite: 235] [cite\_start]With data over a longer period of time (months) this worked very well, but over shorter periods of time (days) it did not. [cite: 236]

Collins et al. (2020) [cite\_start]also studied IoT data, only they used the natural network structure of the data, inducing a filtration with the inter-packet arrival time (IAT), a feature which has been previously shown to contain valuable information for traffic classification and anomaly detection (Uluagac et al. 2013). [cite: 237] [cite\_start]By using the intrinsic structure of the data, they got rid of the need to compute the often prohibitively expensive Rips complex (Figure 6a). [cite: 238] [cite\_start]Next they computed the 1-persistent homology of the filtration. [cite: 239] [cite\_start]Finally they vectorised the persistence diagrams by mapping them to persistence images (Figure 6b), and used those to train a CNN. [cite: 239] [cite\_start]With these higher-dimensional topological features, they were able to identify IoT devices with high accuracy, recall, and precision. [cite: 240]

-----

[cite\_start]**Figure 6:** The 1-persistent homology of packet data can be used to accurately fingerprint IoT devices on networks, even when the traffic is encrypted. [cite: 253] (a) [cite\_start]A simplicial complex built from packet data. [cite: 252] (b) [cite\_start]Examples of 1-persistence images of encrypted packet data. [cite: 253] Reproduced with permission from Collins et al. (2020)[cite\_start]. [cite: 254]

-----

## [cite\_start]6 Graph metrics for cybersecurity [cite: 241]

[cite\_start]Aksoy, Purvine, and Young (2021) introduced a new centrality measure for graphs based on the derivative of the graph Laplacian. [cite: 242] [cite\_start]The kernel of the Laplacian is exactly the 0-homology group, whilst the non-zero image is known to contain rich geometric descriptors of the graph. [cite: 243] [cite\_start]Therefore by using the Laplacian we capture both topological and geometric information about the network. [cite: 244] [cite\_start]Their centrality measure can detect synthetic anomalies that have been injected into the network data. [cite: 245]

[cite\_start]Another measure to compare graphs is the relative Hausdorff distance. [cite: 246] [cite\_start]This offers a fast but nuanced way to compare two graphs based on their complementary cumulative degree histograms (CCDH). [cite: 247] [cite\_start]The CCDH of a graph G is $(N(k))\_{k=1}^{\\infty}$, where $N(k)$ denotes the number of vertices in G with degree at least k. [cite: 248, 255] Comparing the CCDHs gives us the relative Hausdorff distance, which Aksoy et al. (2019) [cite\_start]used to detect anomalies in graph sequences built from the Los Alamos dataset (see Appendix A). [cite: 255, 256] [cite\_start]They built authentication graphs, authentication failure graphs, process graphs, DNS graphs, and flow graphs. [cite: 257] [cite\_start]Over longer time windows, they found that a spike in pairwise RH distance is indicative of a red-team event. [cite: 258]

## [cite\_start]7 Conclusion [cite: 259]

[cite\_start]In this review we have introduced Mapper and persistent homology, and reviewed how they have been applied to cybersecurity problems. [cite: 260] [cite\_start]Mapper has mainly been used for visualisation, providing an effective way for analysts to get a better grasp of large datasets and suggesting data points for further investigation. [cite: 261] [cite\_start]However, it is hard to critically evaluate the success of these techniques, as the papers offer no robust feedback on how useful analysts find the visualisations. [cite: 262] [cite\_start]Coudriau, Lahmadi, and François (2016) clustered the Mapper graph of network telescope data, showing that each cluster represents individual attack types. [cite: 263] [cite\_start]This demonstrates the potential of Mapper for unsupervised classification of anomalies in network data. [cite: 264]

[cite\_start]We have also seen that persistent homology can work on cybersecurity data. [cite: 265] [cite\_start]Bruillard, Nowak, and Purvine (2016) showed that topological dissimilarity can detect anomalous events taking place in network data using the 0-persistent homology: a spike in topological dissimilarity indicated port scans or DDoS attacks in the network logs. [cite: 266] Collins et al. (2020) [cite\_start]built simplicial complexes directly from the intrinsic network structure in the data, training CNNs on the 1-persistence images. [cite: 267] [cite\_start]This demonstrated that higher order topological features can be used in cybersecurity, as they are able to very accurately fingerprint devices using just topological representations of encrypted network traffic. [cite: 268]

[cite\_start]There is a lot of scope for further work in applying topological data analysis to cybersecurity. [cite: 269] [cite\_start]In particular, current literature on persistent homology demonstrates that it is able to use TDA's ability to concisely summarise global structure to perform valuable tasks in cybersecurity. [cite: 270] [cite\_start]We hope that this review brings more attention to TDA from people working on Al in cybersecurity. [cite: 271]

## [cite\_start]A List of datasets [cite: 272]

[cite\_start]We have compiled a list of datasets that may be of interest to researchers in TDA for cybersecurity. [cite: 273] [cite\_start]Some of them are described in a review paper by Yavanoglu and Aydos (2017). [cite: 274]

  * [cite\_start]**KDD Cup 1999** provides TCP connections, content features suggested by domain knowledge, and traffic features, along with labels for anomaly detection (Lippmann et al. 2000). [cite: 275] [cite\_start]It is a very popular dataset for anomaly detection (although fairly outdated these days) and is available online at [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html). [cite: 276] [cite\_start]It is based on the data captured for the DARPA'98 IDS evaluation program. [cite: 277]
  * [cite\_start]**ECML-PKDD 2007** provides requests to web servers and was designed for identifying web attacks with machine learning (Dray et al. 2007). [cite: 278] [cite\_start]It is real-world data that has been manually processed and is available at [https://gitlab.fing.edu.uy/gsi/web-application-attacks-datasets](https://gitlab.fing.edu.uy/gsi/web-application-attacks-datasets). [cite: 279]
  * [cite\_start]**CSIC 2010** is another dataset for web attacks and is based off real data from an e-commerce application. [cite: 280] [cite\_start]It is also available at [https://gitlab.fing.edu.uy/gsi/web-application-attacks-datasets](https://gitlab.fing.edu.uy/gsi/web-application-attacks-datasets). [cite: 281]
  * [cite\_start]**ISOT Botnet and Ransomware** provides DNS queries for 9 botnets plus 19 malign applications, and 420GB of ransomware and benign program execution traces. [cite: 282] [cite\_start]It is available at [https://www.uvic.ca/ecs/ece/isot/datasets/botnet-ransomware/index.php](https://www.google.com/search?q=https://www.uvic.ca/ecs/ece/isot/datasets/botnet-ransomware/index.php). [cite: 283]
  * [cite\_start]**CTU-13** consists of network logs for botnets, verified normal hosts, and unverified background noise (Garcia et al. 2014). [cite: 284] [cite\_start]It is available at [https://www.stratosphereips.org/datasets-ctu13](https://www.stratosphereips.org/datasets-ctu13). [cite: 285]
  * [cite\_start]**ADFA** was compiled in 2013 to update intrusion detection datasets like KDD Cup that were over a decade old. [cite: 286] [cite\_start]The data consists of labelled system calls and is split into Linux, Windows, and Windows stealth attacks. [cite: 287] [cite\_start]It is available at [https://research.unsw.edu.au/projects/adfa-ids-datasets](https://research.unsw.edu.au/projects/adfa-ids-datasets). [cite: 288]
  * [cite\_start]**UNSW-NB15** is a comprehensive dataset that covers a variety of different attacks and is aimed at training and evaluating intrusion detection systems (Moustafa, Turnbull, and Choo 2019). [cite: 289] [cite\_start]It is available at [https://research.unsw.edu.au/projects/unsw-nb15-dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset). [cite: 290]
  * [cite\_start]**DARPA Operationally Transparent Cyber (OpTC)** is a dataset of event logs from 1000 hosts that have a period of baseline activity, followed by having malware injected by a red team. [cite: 291] [cite\_start]It is available at [https://github.com/FiveDirections/OpTC-data](https://github.com/FiveDirections/OpTC-data). [cite: 292]
  * [cite\_start]**LANL ARCS**, the Los Alamos National Lab Advanced Research in Cyber Systems dataset, consists of three separate datasets and is available at [https://csr.lanl.gov/data/](https://csr.lanl.gov/data/). [cite: 293] [cite\_start]The datasets are: [cite: 294]
      * [cite\_start]**Comprehensive, Multi-Source Cyber-Security Events**, consisting of DNS and event data from across the LANL internal network, including labelled red team anomalies; [cite: 295]
      * [cite\_start]**Unified Host and Network Data Set**, consisting of network data from the LANL internal network; [cite: 296]
      * [cite\_start]**User-Computer Authentication Associations in Time**, which consists of around 700 million successful authentication events from the LANL enterprise network. [cite: 297]
  * [cite\_start]**BETH** is a recent anomaly detection dataset created by collecting over eight million DNS logs and kernel level events from 23 honeypots (Highnam et al. 2021). [cite: 298] [cite\_start]The data is real-life, contemporary and provided in a consistent format, and is available at [https://www.kaggle.com/katehighnam/beth-dataset](https://www.kaggle.com/katehighnam/beth-dataset). [cite: 299]

## [cite\_start]Acknowledgements [cite: 300]

[cite\_start]This research was supported by the Defence and Security programme at the Alan Turing Institute, funded by the UK Government. [cite: 301]

## [cite\_start]References [cite: 302]

  * Akcora, C. G.; Li, Y.; [cite\_start]Gel, Y. R.; and Kantarcioglu, M. 2020. BitcoinHeist: Topological Data Analysis for Ransomware Prediction on the Bitcoin Blockchain. [cite: 303] [cite\_start]In Bessiere, C., ed., Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, 4439-4445. [cite: 304] [cite\_start]International Joint Conferences on Artificial Intelligence Organization. [cite: 305] [cite\_start]Special Track on Al in FinTech. [cite: 305]
  * Aksoy, S. G.; Nowak, K. E.; [cite\_start]Purvine, E.; and Young, S. J. 2019. Relative Hausdorff distance for network analysis. [cite: 306] [cite\_start]Applied Network Science, 4(1): 1-25. [cite: 307]
  * Aksoy, S. G.; [cite\_start]Purvine, E.; and Young, S. J. 2021. Directional Laplacian Centrality for Cyber Situational Awareness. [cite: 308] [cite\_start]Digital Threats: Research and Practice (DTRAP), 2(4): 1-28. [cite: 309]
  * Battaglia, P. W.; Pascanu, R.; Lai, M.; [cite\_start]Rezende, D.; and Kavukcuoglu, K. 2016. Interaction networks for learning about objects, relations and physics. [cite: 310] [cite\_start]NeurIPS. [cite: 310]
  * Bihl, T.; Gutierrez, R.; Bauer, K.; [cite\_start]Boehmke, B.; and Saie, C. 2020. Topological Data Analysis for Enhancing Embedded Analytics for Enterprise Cyber Log Analysis and Forensics. [cite: 311] [cite\_start]1937-1946. [cite: 312] [cite\_start]Proceedings of the 53rd Hawaii International Conference on System Sciences. [cite: 312]
  * Bruillard, P.; [cite\_start]Nowak, K.; and Purvine, E. 2016. Anomaly Detection Using Persistent Homology. [cite: 313] [cite\_start]In 2016 Cybersecurity Symposium (CYBERSEC), 7-12. [cite: 313]
  * Bubenik, P.; et al. 2015. [cite\_start]Statistical topological data analysis using persistence landscapes. [cite: 314] J. Mach. Learn. [cite\_start]Res., 16(1): 77-102. [cite: 314]
  * Chepushtanova, S.; Emerson, T.; Hanson, E.; Kirby, M.; Motta, F.; Neville, R.; Peterson, C.; [cite\_start]Shipman, P.; and Ziegelmeier, L. 2015. Persistence Images: An Alternative Persistent Homology Representation. [cite: 315, 316]
  * Chiang, W.-L.; Liu, X.; Si, S.; Li, Y.; Bengio, S.; and Hsieh, C.-J. 2019. [cite\_start]Cluster-gen: An efficient algorithm for training deep and large graph convolutional networks. [cite: 317, 318] [cite\_start]In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 257-266. [cite: 319]
  * Collins, J. R.; Iorga, M.; [cite\_start]Cousin, D.; and Chapman, D. 2020. Passive Encrypted IoT Device Fingerprinting with Persistent Homology. [cite: 320] [cite\_start]UMBC Faculty Collection. [cite: 321]
  * Coudriau, M.; [cite\_start]Lahmadi, A.; and François, J. 2016. Topological analysis and visualisation of network monitoring data: Darknet case study. [cite: 322] [cite\_start]In 2016 IEEE International Workshop on Information Forensics and Security (WIFS), 1-6. [cite: 323]
  * Dray, G.; Raissi, C.; Brissaud, J.; Poncelet, P.; [cite\_start]Roche, M.; and Teisseire, M. 2007. Web Analysis Traffic Challenge: Description and Results. [cite: 324, 325] [cite\_start]In Discovery Challenge ECML/PKDD. [cite: 325]
  * [cite\_start]Edelsbrunner, H.; and Harer, J. 2010. Computational Topology an Introduction. [cite: 326] [cite\_start]American Mathematical Society. [cite: 326] [cite\_start]ISBN 978-0-8218-4925-5. [cite: 326]
  * Edelsbrunner, H.; [cite\_start]Letscher, D.; and Zomorodian, A. 2000. Topological persistence and simplification. [cite: 327] [cite\_start]volume 28, 454 463. [cite: 327] [cite\_start]ISBN 0-7695-0850-2. [cite: 327]
  * [cite\_start]Fachkha, C.; and Debbabi, M. 2015. Darknet as a Source of Cyber Intelligence: Survey, Taxonomy and Characterization. [cite: 328] [cite\_start]IEEE Communications Surveys & Tutorials, 18: 1-1. [cite: 329]
  * Frasca, F.; Rossi, E.; Eynard, D.; Chamberlain, B.; [cite\_start]Bronstein, M.; and Monti, F. 2020. Sign: Scalable inception graph neural networks. [cite: 330, 331] [cite\_start]ICML workshop on Graph Representation Learning and Beyond. [cite: 331]
  * [cite\_start]Gabdrakhmanova, N. 2018. Constructing a Neural-Net Model of Network Traffic Using the Topologic Analysis of Its Time Series Complexity. [cite: 332] In Kryzhanovsky, B.; [cite\_start]Dunin-Barkowski, W.; and Redko, V., eds., Advances in Neural Computation, Machine Learning, and Cognitive Research, 91-97. [cite: 333] [cite\_start]Cham: Springer International Publishing. [cite: 334]
  * Garcia, S.; Grill, M.; [cite\_start]Stiborek, J.; and Zunino, A. 2014. An empirical comparison of botnet detection methods. [cite: 335] [cite\_start]computers & security, 45: 100-123. [cite: 336]
  * [cite\_start]Grover, A.; and Leskovec, J. 2016. node2vec: Scalable feature learning for networks. [cite: 337] [cite\_start]In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 855-864. [cite: 338]
  * Gutierrez, R. J.; Bauer, K. W.; Boehmke, B. C.; [cite\_start]Saie, C. M.; and Bihl, T. J. 2018. Cyber anomaly detection: Using tabulated vectors and embedded analytics for efficient data mining. [cite: 339, 340] [cite\_start]Journal of Algorithms & Computational Technology, 12(4): 293-310. [cite: 341]
  * Hamilton, W. L.; [cite\_start]Ying, R.; and Leskovec, J. 2017. Inductive representation learning on large graphs. [cite: 342] [cite\_start]In Proceedings of the 31st International Conference on Neural Information Processing Systems, 1025-1035. [cite: 343]
  * [cite\_start]Hatcher, A. 2000. Algebraic topology. [cite: 344] Cambridge: Cambridge Univ. [cite\_start]Press. [cite: 344]
  * Highnam, K.; Arulkumaran, K.; [cite\_start]Hanif, Z.; and Jennings, N. R. 2021. BETH Dataset: Real Cybersecurity Data for Anomaly Detection Research. [cite: 345] [cite\_start]ICML Workshop on Uncertainty and Robustness in Deep Learning. [cite: 346]
  * Islambekov, U.; [cite\_start]Yuvaraj, M.; and Gel, Y. R. 2019. Harnessing the power of Topological Data Analysis to detect change points in time series. [cite: 347] [cite\_start]arXiv preprint arXiv:1910.12939. [cite: 348]
  * [cite\_start]Jakub, B.; and Branišová, J. 2015. Anomaly Detection from Log Files Using Data Mining Techniques. [cite: 348] [cite\_start]Lecture Notes in Electrical Engineering, 339: 449-457. [cite: 349]
  * [cite\_start]Kipf, T. N.; and Welling, M. 2017. Semi-Supervised Classification with Graph Convolutional Networks. [cite: 350] [cite\_start]In International Conference on Learning Representations (ICLR). [cite: 351]
  * Lerer, A.; Wu, L.; Shen, J.; Lacroix, T.; [cite\_start]Wehrstedt, L.: Bose, A.; and Peysakhovich, A. 2019. PyTorch-BigGraph: A Large-scale Graph Embedding System. [cite: 352, 353] [cite\_start]In Proceedings of the 2nd SysML Conference. [cite: 353] [cite\_start]Palo Alto, CA, USA. [cite: 354]
  * Lippmann, R. P.; Fried, D. J.; Graf, I.; Haines, J. W.; Kendall, K. R.; McClung, D.; Weber, D.; Webster, S. E.; Wyschogrod, D.; Cunningham, R. K.; et al. 2000. [cite\_start]Evaluating intrusion detection systems: The 1998 DARPA off-line intrusion detection evaluation. [cite: 355, 356, 357] [cite\_start]In Proceedings DARPA Information Survivability Conference and Exposition. [cite: 358] [cite\_start]DISCEX'00, volume 2, 12-26. [cite: 358] [cite\_start]IEEE. [cite: 358]
  * Lum, P.; Singh, G.; Lehman, A.; Ishkanov, T.; Vejdemo-Johansson, M.; Alagappan, M.; [cite\_start]Carlsson, J.; and Carlsson, G. 2013. Extracting insights from the shape of complex data using topology. [cite: 359, 360] [cite\_start]Scientific Reports, 3. [cite: 360]
  * Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013a. [cite\_start]Efficient estimation of word representations in vector space. [cite: 361] [cite\_start]ICLR workshop. [cite: 362]
  * Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013b. [cite\_start]Distributed representations of words and phrases and their compositionality. [cite: 363, 364] [cite\_start]In Advances in neural information processing systems, 3111-3119. [cite: 364]
  * Monti, F.; Boscaini, D.; Masci, J.; Rodola, E.; [cite\_start]Svoboda, J.; and Bronstein, M. M. 2017. Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs. [cite: 365, 366] [cite\_start]In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5425-5434. [cite: 367] [cite\_start]Los Alamitos, CA, USA: IEEE Computer Society. [cite: 367]
  * Moustafa, N.; Turnbull, B.; and Choo, K.-K. [cite\_start]R. 2019. An Ensemble Intrusion Detection Technique Based on Proposed Statistical Flow Features for Protecting Network Traffic of Internet of Things. [cite: 368] [cite\_start]IEEE Internet of Things Journal, 6(3): 4815-4830. [cite: 369]
  * [cite\_start]Nanda, V. 2021. Computational Algebraic Topology lecture notes. [http://people.maths.ox.ac.uk/nanda/cat/TDANotes.pdf](http://people.maths.ox.ac.uk/nanda/cat/TDANotes.pdf). [cite: 370] [cite\_start]Accessed: 2021-09-17. [cite: 370]
  * [cite\_start]Narita, M. 2021. An Empirical Study on Darknet Visualization Based on Topological Data Analysis. [cite: 371] [cite\_start]International Journal of Networked and Distributed Computing, 9: 52-58. [cite: 372]
  * Navarro, J.; Legrand, V.; Lagraa, S.; François, J.; Lahmadi, A.; Santis, G.; Festor, O.; Lammari, N.; Hamdi, F.; Deruyver, A.; Goux, Q.; [cite\_start]Allard, M.; and Parrend, P. 2018. HuMa: A Multi-layer Framework for Threat Analysis in a Heterogeneous Log Environment, 144-159. [cite: 373, 374] [cite\_start]ISBN 978-3-319-75649-3. [cite: 375]
  * Nicolau, M.; [cite\_start]Levine, A. J.; and Carlsson, G. 2011. Topology based data analysis identifies a subgroup of breast cancers with a unique mutational profile and excellent survival. [cite: 376] [cite\_start]Proceedings of the National Academy of Sciences, 108(17): 7265-7270. [cite: 377]
  * Postol, M.; Diaz, C.; [cite\_start]Simon, R.; and Wicke, D. 2019. Time-series data analysis for classification of noisy and incomplete Internet-of-Things datasets. [cite: 378] [cite\_start]In 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), 1543-1550. [cite: 379] [cite\_start]IEEE. [cite: 379]
  * Rieck, B.; [cite\_start]Sadlo, F.; and Leitte, H. 2017. Topological machine learning with persistence indicator functions. [cite: 380] [cite\_start]In Topological Methods in Data Analysis and Visualization, 87-101. [cite: 381] [cite\_start]Springer. [cite: 381]
  * [cite\_start]Rizzo, N. 2020. Topological Data Analysis for Evaluation of Network Security Data. [cite: 382] [cite\_start]Master's thesis, State University of New York at Albany. [cite: 383]
  * Singh, G.; [cite\_start]Mémoli, F.; and Carlsson, G. 2007. Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. [cite: 384] [cite\_start]In PBG@Eurographics. [cite: 385]
  * Tang, J.; Qu, M.; Wang, M.; Zhang, M.; [cite\_start]Yan, J.; and Mei, Q. 2015. Line: Large-scale information network embedding. [cite: 386] [cite\_start]In Proceedings of the 24th international conference on world wide web, 1067-1077. [cite: 387]
  * Uluagac, A. S.; Radhakrishnan, S. V.; Corbett, C.; [cite\_start]Baca, A.; and Beyah, R. 2013. A passive technique for fingerprinting wireless devices with wired-side observations. [cite: 388, 389] [cite\_start]In 2013 IEEE conference on communications and network security (CNS), 305-313. [cite: 390] [cite\_start]IEEE. [cite: 390]
  * [cite\_start]van Veen, H. 2018. Detecting Encrypted TOR Traffic with Boosting and Topological Data Analysis. [https://kepler-mapper.scikit-tda.org/en/latest/notebooks/TORXGB-TDA.html](https://www.google.com/search?q=https://kepler-mapper.scikit-tda.org/en/latest/notebooks/TORXGB-TDA.html). [cite: 391] [cite\_start]Accessed: 2021-09-15. [cite: 391]
  * [cite\_start]Vietoris, L. 1927. Über den höheren Zusammenhang kompakter Röume und eine Klasse von zusammenhangstreuen. [cite: 392] Abbildungen. [cite\_start]Mathematische Annalen, 97(1): 454-472. [cite: 392]
  * Winding, R. M.; [cite\_start]Wright, T. E.; and Chapple, M. 2006. System Anomaly Detection: Mining Firewall Logs. [cite: 393] [cite\_start]2006 Securecomm and Workshops, 1-5. [cite: 394]
  * [cite\_start]Yavanoglu, O.; and Aydos, M. 2017. A Review on Cyber Security Datasets for Machine Learning Algorithms. [cite: 395]
  * Zeng, H.; Zhou, H.; Srivastava, A.; [cite\_start]Kannan, R.; and Prasanna, V. 2020. GraphSAINT: Graph Sampling Based Inductive Learning Method. [cite: 396] [cite\_start]In International Conference on Learning Representations. [cite: 397]
  * Zhao, Q.; Ye, Z.; [cite\_start]Chen, C.; and Wang, Y. 2020. Persistence Enhanced Graph Neural Network. [cite: 398] [cite\_start]In Chiappa, S.; and Calandra, R., eds., Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, 2896-2906. [cite: 399] [cite\_start]PMLR. [cite: 400]